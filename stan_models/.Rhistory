rstan:::rstudio_stanc("v_resid2.stan")
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_rva <- "~/projects/RVA/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
library(sigmoid)
library(posterior)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-06_14_00_57.801362.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-06_14_00_57.801362.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 80)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 3,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .07, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="vrat_number",val_col="val_rat") #add valence rating number
trials <- add_probe_number(trials,newcol="prat_number",val_col="prob_rat") #add probability rating number
trials$prev_vrat_cent <- trials$prev_rate - mean(trials$prev_rate,na.rm=T)
trials <- trials %>% mutate(frac_ix = case_when(
frac_img == 1 ~ 1,
frac_img == 9 ~ 2,
frac_img == 3 ~ 3,
frac_img == 5 ~ 4,
)) %>%
mutate(alt_frac_ix = case_when(
frac_ix == 1 ~ 2,
frac_ix == 2 ~ 1,
frac_ix == 3 ~ 4,
frac_ix == 4 ~ 3
))
view(filt_sum(v_resid2$sum,"mu"))
B_V_r_mu <- get_draws("v_resid2",vars=c("B_V_r_mu"))
B_V_r_mu <- get_draws("v_resid2",vars=c("B_V_r_mu"))
B_V_r_mu <- get_draws("v_resid2",vars=c("B_V_r_mu"),model_out_dir=model_out_dir)
B_V_r_mu <- get_draws("v_resid2",vars=c("B_V_r_mu"),model_out_dir=model_out_dir)
B_V_alt_r_mu <- get_draws("v_resid2",vars=c("B_V_alt_r_mu"),model_out_dir=model_out_dir)
B_alt_r_mu <- get_draws("v_resid2",vars=c("B_alt_r_mu"),model_out_dir=model_out_dir)
mean(B_V_r_mu>0)
prereg_rva2 <- read_fsml("prereg_rva2",model_out_dir=model_out_dir)
view(filt_sum(prereg_rva2$sum,"mu"))
mean(B_V_r_mu > B_V_alt_r_mu)
mean(B_V_r_mu > B_alt_r_mu)
raw_effs <- get_draws("v_resid2",vars=c("B_V_r_mu","B_alt_r_mu","B_V_mu","B_alt_mu","B_rew_mu"),model_out_dir=model_out_dir)
create_interval_plot(arr = raw_effs, names = c("B_V_r_mu","B_alt_r_mu","B_V_mu","B_alt_mu","B_rew_mu"), xmin = -.012, xmax = 1)
create_interval_plot(arr = raw_effs, names = c("B_V_r_mu","B_alt_r_mu","B_V_mu","B_alt_mu","B_rew_mu"), xmin = -.01, xmax = .1)
create_interval_plot(arr = raw_effs, names = c(,"B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -.01, xmax = .1)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -.01, xmax = .1)
raw_effs[,,"B_V_mu"] > raw_effs[,,"B_alt_mu"]
mean(raw_effs[,,"B_V_mu"] > raw_effs[,,"B_alt_mu"])
mean(raw_effs[,,"B_V_mu"] > raw_effs[,,"B_V_r_mu"])
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -.01, xmax = .04)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -.01, xmax = .035)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = 0, xmax = .035)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = 0.01, xmax = .035)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -0.01, xmax = .035)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -0.05, xmax = .035)
create_interval_plot(arr = raw_effs, names = c("B_alt_r_mu","B_V_r_mu","B_alt_mu","B_V_mu","B_rew_mu"), xmin = -0.005, xmax = .035)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_rva <- "~/projects/RVA/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
library(sigmoid)
library(posterior)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-06_14_00_57.801362.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-06_14_00_57.801362.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 80)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 3,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .07, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
nrow(subs)
nrow(subs)+length(subs_to_exclude)
nrow(trials)/102
vp_resid<- get_draws("v_resid2",model_out_dir=model_out_dir,vars=c("val_pred"))
vss_resid <- get_draws("v_resid2",model_out_dir=model_out_dir,vars=c("val_sigma_sigma"))
vs_resid <- apply(vss_resid,c(1,2,3),half_normal_mean)
val_rsq_resid <- mcmc_rsq(vp_resid,vs_resid,print_plot=FALSE)
val_rsq_resid$sum[['median']]
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/spring_2022_study/"
path_to_fu_project_directory <- "~/projects/s22_follow_up/"
path_to_bv_project_directory <- "~/projects/ARL_BV/"
##############
stan_model_dir <- paste0(path_to_project_directory,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_models/")
model_out_dir_fu <- paste0(path_to_fu_project_directory,"output/results/stan_model_fits/")
fig_dir <- "/Users/dp/Documents/manuscripts/vrv/figures_tables/"
library(cmdstanr)
library(tidyverse)
library(bayesplot)
library(tidybayes)
library(grid)
library(abind)
library(patchwork)
library(sigmoid)
library(future)
library(doFuture)
library(foreach)
source(paste0(path_to_project_directory,"code/functions/s22_utilities.R"))
source(paste0(path_to_bv_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/stan_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2022-05-22_19_14_57.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2022-05-22_19_14_57.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed == 0 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 126 |
probe_skipped_percent > .14 |
id %in% c(86956,86746,86839,80227,79198,86503,86869,85588))
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] == 1,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$probe_skipped_percent[i] > .07,subs$noprobe_pt_choices[i] == 0,subs$probe_pt_choices[i] == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
#trials <- trials %>% filter(!(id %in% c(86077,86134,86356,87163,86458,85588,86869,86956,86746,79198,86359,86503,86881))) %>% filter(choice != "late")
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#convert affect ratings to subject-by-subject z-scores, to control for intersubject differences in rating variability
trials[c("valence_dec","valence_feed")] <- trials[c("valence_dec","valence_feed")]*-1 #flip the affect ratings, so that the low numbers
#correspond to low values of valence
trials <- do.call(rbind,by(trials,trials$id,col_zscore,c("valence_dec","valence_feed"))) #translate valence ratings to z-scores
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="valence_dec",arous_col="arousal_dec") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="valence_feed",arous_col="arousal_feed") #for feedback probes
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
trials <- trials %>% mutate(dec_probe_completed = if_else(is.na(arousal_dec) | is.na(valence_dec),0,1)) #add a 1/0 column indicating whether a
#decision probe was completed on each trial
trials <- trials %>% mutate(feed_probe_completed = if_else(is.na(arousal_feed) | is.na(valence_feed),0,1)) #diddo feedback
#get mean-centeedr trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fractal_a_dec",fractal_a_num,fractal_b_num))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fractal_a_dec",fractal_b_num,fractal_a_num))
#add columns showing the pairs at play in each block
new_trials_list <- by(trials,trials$id,create_pair_cols_sub)
trials <- do.call(rbind,new_trials_list)
exdecay_trial_full_learnV_centshrink <- read_fsml("exdecay_trial_full_learnV_centshrink",model_out_dir=model_out_dir)
filt_sum(exdecay_trial_full_learnV_centshrink$sum,"mu")
view(filt_sum(exdecay_trial_full_learnV_centshrink$sum,"mu"))
nrow(trials)
9954/101
nrow(subs)
9954/79
126/2
63*-0.004592505
block <- get_draws("exdecay_trial_full_learnV_centshrink",model_out_dir=model_out_dir,"tw_mu[1]")
trial <- get_draws("exdecay_trial_full_learnV_centshrink",model_out_dir=model_out_dir,"tw_mu[2]")
mean(trial*63 > block)
.004*63
head(trials$block_nc)
head(trials$block_cent)
head(trials$trial_nl_cent)
sd(-0.5,0.5)
sd(c(-0.5,0.5))
(1/.7)
0.094421900*1.4
sd(c(-31,31))
43*-0.004592505
mean(trial < 0)
mean(block < 0)
sigmoid(2)
library(sigmoid)
sigmoid(2)
sigmoid(1.5)
sigmoid(-1)
sigmoid(-1)
sigmoid(1)
sigmoid(0)
sigmoid(2)
sigmoid(-2)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/spring_2022_study/"
path_to_fu_project_directory <- "~/projects/s22_follow_up/"
path_to_bv_project_directory <- "~/projects/ARL_BV/"
##############
stan_model_dir <- paste0(path_to_project_directory,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_models/")
model_out_dir_fu <- paste0(path_to_fu_project_directory,"output/results/stan_model_fits/")
fig_dir <- "/Users/dp/Documents/manuscripts/vrv/figures_tables/"
library(cmdstanr)
library(tidyverse)
library(bayesplot)
library(tidybayes)
library(grid)
library(abind)
library(patchwork)
library(sigmoid)
library(future)
library(doFuture)
library(foreach)
source(paste0(path_to_project_directory,"code/functions/s22_utilities.R"))
source(paste0(path_to_bv_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/stan_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2022-05-22_19_14_57.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2022-05-22_19_14_57.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed == 0 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 126 |
probe_skipped_percent > .14 |
id %in% c(86956,86746,86839,80227,79198,86503,86869,85588))
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] == 1,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$probe_skipped_percent[i] > .07,subs$noprobe_pt_choices[i] == 0,subs$probe_pt_choices[i] == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
#trials <- trials %>% filter(!(id %in% c(86077,86134,86356,87163,86458,85588,86869,86956,86746,79198,86359,86503,86881))) %>% filter(choice != "late")
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#convert affect ratings to subject-by-subject z-scores, to control for intersubject differences in rating variability
trials[c("valence_dec","valence_feed")] <- trials[c("valence_dec","valence_feed")]*-1 #flip the affect ratings, so that the low numbers
#correspond to low values of valence
trials <- do.call(rbind,by(trials,trials$id,col_zscore,c("valence_dec","valence_feed"))) #translate valence ratings to z-scores
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="valence_dec",arous_col="arousal_dec") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="valence_feed",arous_col="arousal_feed") #for feedback probes
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
trials <- trials %>% mutate(dec_probe_completed = if_else(is.na(arousal_dec) | is.na(valence_dec),0,1)) #add a 1/0 column indicating whether a
#decision probe was completed on each trial
trials <- trials %>% mutate(feed_probe_completed = if_else(is.na(arousal_feed) | is.na(valence_feed),0,1)) #diddo feedback
#get mean-centeedr trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fractal_a_dec",fractal_a_num,fractal_b_num))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fractal_a_dec",fractal_b_num,fractal_a_num))
#add columns showing the pairs at play in each block
new_trials_list <- by(trials,trials$id,create_pair_cols_sub)
trials <- do.call(rbind,new_trials_list)
etflc <- read_fsml("exdecay_trial_full_learnV_centshrink",model_out_dir=model_out_dir)
view(filt_sum(etflc$sum,"sigma"))
view(filt_sum(etflc$sum,"mu"))
2/60
2/45
.04*45
sigmoid(-1.8)
sigmoid(-1.5)
sigmoid(-1)
sd(c(0,1))
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
rstan:::rstudio_stanc("~/projects/RVA_3/prereg_rva3.stan")
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-04-23_14_16_47.570477.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-04-23_14_16_47.570477.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 2 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 84)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 2,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .10, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="vrat_number",val_col="val_rat") #add valence rating number
trials <- add_probe_number(trials,newcol="prat_number",val_col="prob_rat") #add probability rating number
trials$prev_vrat_cent <- trials$prev_rate - mean(trials$prev_rate,na.rm=T)
trials_lags <- trials %>%
group_by(id, block) %>%
mutate(outcome_a = ifelse(frac_ix = ))
names(trials)
trials_lags <- trials %>%
group_by(id, block) %>%
group_modify(~ add_lag_cols(.x, "outcome")) %>%
ungroup()
trials_lags <- trials %>%
group_by(id, block) %>%
group_modify(~ add_lag_cols(.x, "out_a")) %>%
ungroup()
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag2 + out_a_lag3 + out_a_lag4,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag2 + out_a_lag3 + out_a_lag4 + out_a_lag5,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag2 + out_a_lag3 + out_a_lag4 + out_a_lag5 + out_a_lag6,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5,trials_lags))
trials_lags <- trials %>%
group_by(id, block) %>%
group_modify(~ add_lag_cols(.x, "out_a"),lag_cols=c(1:9)) %>%
ungroup()
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
trials_lags <- trials %>%
group_by(id, block) %>%
group_modify(~ add_lag_cols(.x, "out_a",lag_cols=c(1:9)))%>%
ungroup()
trials_lags <- trials %>%
group_by(id, block) %>%
group_modify(~ add_lag_cols(.x, "out_a",lags=c(1:9)))%>%
ungroup()
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag2 + out_a_lag3 + out_a_lag4 + out_a_lag5,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag2 + out_a_lag4 + out_a_lag6,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag2 + out_a_lag4 + out_a_lag6 + + out_a_lag8,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
.86^5
.86^9
.86^10
trials_lags <- trials %>%
group_by(id, block) %>%
group_modify(~ add_lag_cols(.x, "out_a",lags=c(1:13)))%>%
ungroup()
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + out_a_lag11 + out_a_lag13,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag2 + out_a_lag3 + out_a_lag4 + out_a_lag5 + out_a_lag6 + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag2 + out_a_lag4 + out_a_lag5 + out_a_lag8,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag2 + out_a_lag4 + out_a_lag5 + out_a_lag8,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_valrat_z,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_valrat,trials_lags))
names(trials_lags)
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
+ prev_vrat_cent
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(prob_rat ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(prob_rat ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(prob_rat ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(val_rat ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(prob_rat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
names(trials)
trials_lags$probrat_z <- trials_lags$prob_rat/sd(trials_lags$prob_rat,na.rm = T) - mean(trials_lags$prob_rat,na.rm=T)
summary(lm(prob_rat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(probrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 +prevrat_z,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prevrat_cent,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + out_a_lag11,trials_lags))
summary(lm(probrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + out_a_lag11,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
+ out_a_lag11
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + out_a_lag11,trials_lags))
summary(lm(valrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9,trials_lags))
summary(lm(probrat_z ~ out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + out_a_lag11,trials_lags))
summary(lm(valrat_z ~ out_a + out_a_lag1 + out_a_lag3 + out_a_lag5 + out_a_lag7 + out_a_lag9 + prev_vrat_cent,trials_lags))
