source("~/projects/RVA_2/code/rva_master_script.R", echo=TRUE)
source("~/projects/RVA_2/code/rva_master_script.R", echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
trials %>%
group_by(sub_index) %>%
summarize(correlation = cor(outcome, val_rat, use = "complete.obs"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-04-23_14_16_47.570477.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-04-23_14_16_47.570477.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 2 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 84)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 2,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .10, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="vrat_number",val_col="val_rat") #add valence rating number
trials <- add_probe_number(trials,newcol="prat_number",val_col="prob_rat") #add probability rating number
trials$prev_vrat_cent <- trials$prev_rate - mean(trials$prev_rate,na.rm=T)
trials %>%
group_by(sub_index) %>%
summarize(correlation = cor(outcome, val_rat, use = "complete.obs"))
trials %>%
group_by(sub_index) %>%
summarize(correlation = cor(out_a, val_rat, use = "complete.obs"))
out_val_cors <- trials %>%
group_by(sub_index) %>%
summarize(correlation = cor(out_a, val_rat, use = "complete.obs"))
hist(out_val_cors)
out_val_cors
hist(out_val_cors$correlation)
mean(out_val_cors$correlation)
median(trials$val_rat_rt,na.rm=T)
#This is the master script for initial data analysis steps
#It identifies data to use, wrangles it into a usable form, creates additional variables based on this data, and creates plots of certain variables for quality-checking.
library(qualtRics)
library(tidyverse)
library(ddpcr)
library(tidyverse)
library(sigmoid)
##SET MANUALLY
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_s22fu <- "~/projects/s22_follow_up/"
path_to_rva <- "~/projects/RVA/"
ids_to_exclude <- c("6398dc9eee4c333e1712e777") #Ps whose data you don't want to analyze even if it looks good
##############
#clear out results from old analyses
system("mv /Users/dp/projects/RVA_2/analysis_data/*.csv /Users/dp/projects/RVA_2/analysis_data/old_analysis_data") #move any CSV files in this folder to old_analysis_data folder
system("rm -rf /Users/dp/projects/RVA_2/analysis_data/qc_plots/trial_level_vars/*") #clear the folder containing trial-level plots
system("rm -f /Users/dp/projects/RVA_2/analysis_data/qc_plots/sub_level_variables.pdf") #remove old subject level variable plot
#read in necessary functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22fu,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_wrangle_psychopy_data.R"))
csvs_to_analyze <- get_csvs_to_analyze(path_to_project_directory,ids_to_exclude,first_time="2024-04-26") #get the usable CSVs to analyze
all_data <- lapply(csvs_to_analyze, rva2_wrangle_psychopy_data) #reformats each CSV, turning it into a long dataset usable for analysis, and adds all variables of interest that can be created from the raw data alone.
#Returns a list - one element for each subject - where each element is itself a list containing dfs with the trial-level data and subject-level data
trials_list <- lapply(all_data, function(l) l[[1]]) #get a list of the trial-level dfs only
trial_level_data <- do.call(rbind,trials_list) #stack trial dfs into one big df
sub_list <- lapply(all_data, function(l) l[[2]]) #get a list of the subject-level dfs only
sub_level_data <- do.call(rbind,sub_list) #stack them into one big data frame
#append the Yes/No answer from qualtrics to this data
sub_level_data <- qualtrics_append(sub_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
trial_level_data <- qualtrics_append(trial_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
#write both to CSVs
date_time <- Sys.time() %>% chartr(" ","_",.) %>% chartr(":","_",.) #grab the date and time, reformatting ':' and '-' to  '_' so you can label the files with it
write.csv(trial_level_data,paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#write subject-level data
write.csv(sub_level_data,paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#Create plot grids of select variables for quality checking. These are saved to the qc_plots folder
tl_hists <- c("val_rat_rt","prob_rat_rt","val_rat","prob_rat") #trial level variables to plot
plot_trial_level_vars(trial_level_data,tl_hists,path_to_project_directory) #create and save plot grids
sl_hists <- c("answers_incorrect","instruct_keypress",
"feed_check_passed","aff_check_passed","worth_check_passed","att_checks_passed",
"probrat_skipped_percent","sd_probrat","mean_probrat_rt",
"valrat_skipped_percent","sd_valrat","mean_valrat_rt",
"earnings","total_experiment_time") #subject-level variables to plot
plot_sub_level_vars(sub_level_data,sl_hists,path_to_project_directory) #create and save plot grids
#This is the master script for initial data analysis steps
#It identifies data to use, wrangles it into a usable form, creates additional variables based on this data, and creates plots of certain variables for quality-checking.
library(qualtRics)
library(tidyverse)
library(ddpcr)
library(tidyverse)
library(sigmoid)
##SET MANUALLY
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_s22fu <- "~/projects/s22_follow_up/"
path_to_rva <- "~/projects/RVA/"
ids_to_exclude <- c("6398dc9eee4c333e1712e777") #Ps whose data you don't want to analyze even if it looks good
##############
#clear out results from old analyses
system("mv /Users/dp/projects/RVA_2/analysis_data/*.csv /Users/dp/projects/RVA_2/analysis_data/old_analysis_data") #move any CSV files in this folder to old_analysis_data folder
system("rm -rf /Users/dp/projects/RVA_2/analysis_data/qc_plots/trial_level_vars/*") #clear the folder containing trial-level plots
system("rm -f /Users/dp/projects/RVA_2/analysis_data/qc_plots/sub_level_variables.pdf") #remove old subject level variable plot
#read in necessary functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22fu,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_wrangle_psychopy_data.R"))
csvs_to_analyze <- get_csvs_to_analyze(path_to_project_directory,ids_to_exclude,first_time="2024-04-26") #get the usable CSVs to analyze
all_data <- lapply(csvs_to_analyze, rva2_wrangle_psychopy_data) #reformats each CSV, turning it into a long dataset usable for analysis, and adds all variables of interest that can be created from the raw data alone.
#Returns a list - one element for each subject - where each element is itself a list containing dfs with the trial-level data and subject-level data
trials_list <- lapply(all_data, function(l) l[[1]]) #get a list of the trial-level dfs only
trial_level_data <- do.call(rbind,trials_list) #stack trial dfs into one big df
sub_list <- lapply(all_data, function(l) l[[2]]) #get a list of the subject-level dfs only
sub_level_data <- do.call(rbind,sub_list) #stack them into one big data frame
#append the Yes/No answer from qualtrics to this data
sub_level_data <- qualtrics_append(sub_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
trial_level_data <- qualtrics_append(trial_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
#write both to CSVs
date_time <- Sys.time() %>% chartr(" ","_",.) %>% chartr(":","_",.) #grab the date and time, reformatting ':' and '-' to  '_' so you can label the files with it
write.csv(trial_level_data,paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#write subject-level data
write.csv(sub_level_data,paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#Create plot grids of select variables for quality checking. These are saved to the qc_plots folder
tl_hists <- c("val_rat_rt","prob_rat_rt","val_rat","prob_rat") #trial level variables to plot
plot_trial_level_vars(trial_level_data,tl_hists,path_to_project_directory) #create and save plot grids
sl_hists <- c("answers_incorrect","instruct_keypress",
"feed_check_passed","aff_check_passed","worth_check_passed","att_checks_passed",
"probrat_skipped_percent","sd_probrat","mean_probrat_rt",
"valrat_skipped_percent","sd_valrat","mean_valrat_rt",
"earnings","total_experiment_time") #subject-level variables to plot
plot_sub_level_vars(sub_level_data,sl_hists,path_to_project_directory) #create and save plot grids
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_rva <- "~/projects/RVA/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
library(sigmoid)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-03_16_50_14.836642.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-03_16_50_14.836642.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 80)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 3,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .07, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
nrow(subs)
#This is the master script for initial data analysis steps
#It identifies data to use, wrangles it into a usable form, creates additional variables based on this data, and creates plots of certain variables for quality-checking.
library(qualtRics)
library(tidyverse)
library(ddpcr)
library(tidyverse)
library(sigmoid)
##SET MANUALLY
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_s22fu <- "~/projects/s22_follow_up/"
path_to_rva <- "~/projects/RVA/"
ids_to_exclude <- c("6398dc9eee4c333e1712e777") #Ps whose data you don't want to analyze even if it looks good
##############
#clear out results from old analyses
system("mv /Users/dp/projects/RVA_2/analysis_data/*.csv /Users/dp/projects/RVA_2/analysis_data/old_analysis_data") #move any CSV files in this folder to old_analysis_data folder
system("rm -rf /Users/dp/projects/RVA_2/analysis_data/qc_plots/trial_level_vars/*") #clear the folder containing trial-level plots
system("rm -f /Users/dp/projects/RVA_2/analysis_data/qc_plots/sub_level_variables.pdf") #remove old subject level variable plot
#read in necessary functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22fu,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_wrangle_psychopy_data.R"))
csvs_to_analyze <- get_csvs_to_analyze(path_to_project_directory,ids_to_exclude,first_time="2024-04-26") #get the usable CSVs to analyze
all_data <- lapply(csvs_to_analyze, rva2_wrangle_psychopy_data) #reformats each CSV, turning it into a long dataset usable for analysis, and adds all variables of interest that can be created from the raw data alone.
#Returns a list - one element for each subject - where each element is itself a list containing dfs with the trial-level data and subject-level data
trials_list <- lapply(all_data, function(l) l[[1]]) #get a list of the trial-level dfs only
trial_level_data <- do.call(rbind,trials_list) #stack trial dfs into one big df
sub_list <- lapply(all_data, function(l) l[[2]]) #get a list of the subject-level dfs only
sub_level_data <- do.call(rbind,sub_list) #stack them into one big data frame
#append the Yes/No answer from qualtrics to this data
sub_level_data <- qualtrics_append(sub_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
trial_level_data <- qualtrics_append(trial_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
#write both to CSVs
date_time <- Sys.time() %>% chartr(" ","_",.) %>% chartr(":","_",.) #grab the date and time, reformatting ':' and '-' to  '_' so you can label the files with it
write.csv(trial_level_data,paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#write subject-level data
write.csv(sub_level_data,paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#Create plot grids of select variables for quality checking. These are saved to the qc_plots folder
tl_hists <- c("val_rat_rt","prob_rat_rt","val_rat","prob_rat") #trial level variables to plot
plot_trial_level_vars(trial_level_data,tl_hists,path_to_project_directory) #create and save plot grids
sl_hists <- c("answers_incorrect","instruct_keypress",
"feed_check_passed","aff_check_passed","worth_check_passed","att_checks_passed",
"probrat_skipped_percent","sd_probrat","mean_probrat_rt",
"valrat_skipped_percent","sd_valrat","mean_valrat_rt",
"earnings","total_experiment_time") #subject-level variables to plot
plot_sub_level_vars(sub_level_data,sl_hists,path_to_project_directory) #create and save plot grids
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_rva <- "~/projects/RVA/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
library(sigmoid)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-03_16_53_54.929421.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-03_16_53_54.929421.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 80)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 3,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .07, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
nrow(subs)
#This is the master script for initial data analysis steps
#It identifies data to use, wrangles it into a usable form, creates additional variables based on this data, and creates plots of certain variables for quality-checking.
library(qualtRics)
library(tidyverse)
library(ddpcr)
library(tidyverse)
library(sigmoid)
##SET MANUALLY
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_s22fu <- "~/projects/s22_follow_up/"
path_to_rva <- "~/projects/RVA/"
ids_to_exclude <- c("6398dc9eee4c333e1712e777") #Ps whose data you don't want to analyze even if it looks good
##############
#clear out results from old analyses
system("mv /Users/dp/projects/RVA_2/analysis_data/*.csv /Users/dp/projects/RVA_2/analysis_data/old_analysis_data") #move any CSV files in this folder to old_analysis_data folder
system("rm -rf /Users/dp/projects/RVA_2/analysis_data/qc_plots/trial_level_vars/*") #clear the folder containing trial-level plots
system("rm -f /Users/dp/projects/RVA_2/analysis_data/qc_plots/sub_level_variables.pdf") #remove old subject level variable plot
#read in necessary functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22fu,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_wrangle_psychopy_data.R"))
csvs_to_analyze <- get_csvs_to_analyze(path_to_project_directory,ids_to_exclude,first_time="2024-09-03") #get the usable CSVs to analyze
all_data <- lapply(csvs_to_analyze, rva2_wrangle_psychopy_data) #reformats each CSV, turning it into a long dataset usable for analysis, and adds all variables of interest that can be created from the raw data alone.
#Returns a list - one element for each subject - where each element is itself a list containing dfs with the trial-level data and subject-level data
trials_list <- lapply(all_data, function(l) l[[1]]) #get a list of the trial-level dfs only
trial_level_data <- do.call(rbind,trials_list) #stack trial dfs into one big df
sub_list <- lapply(all_data, function(l) l[[2]]) #get a list of the subject-level dfs only
sub_level_data <- do.call(rbind,sub_list) #stack them into one big data frame
#append the Yes/No answer from qualtrics to this data
sub_level_data <- qualtrics_append(sub_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
trial_level_data <- qualtrics_append(trial_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
#write both to CSVs
date_time <- Sys.time() %>% chartr(" ","_",.) %>% chartr(":","_",.) #grab the date and time, reformatting ':' and '-' to  '_' so you can label the files with it
write.csv(trial_level_data,paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#write subject-level data
write.csv(sub_level_data,paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#Create plot grids of select variables for quality checking. These are saved to the qc_plots folder
tl_hists <- c("val_rat_rt","prob_rat_rt","val_rat","prob_rat") #trial level variables to plot
plot_trial_level_vars(trial_level_data,tl_hists,path_to_project_directory) #create and save plot grids
sl_hists <- c("answers_incorrect","instruct_keypress",
"feed_check_passed","aff_check_passed","worth_check_passed","att_checks_passed",
"probrat_skipped_percent","sd_probrat","mean_probrat_rt",
"valrat_skipped_percent","sd_valrat","mean_valrat_rt",
"earnings","total_experiment_time") #subject-level variables to plot
plot_sub_level_vars(sub_level_data,sl_hists,path_to_project_directory) #create and save plot grids
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_rva <- "~/projects/RVA/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
library(sigmoid)
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-03_17_46_55.702125.csv"))
nrows(subs)
nrow(subs)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-03_17_46_55.702125.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 80)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 3,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .07, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
nrow(subs)
source("~/projects/ARL_bv/code/functions/arlbv_utilities.R", echo=TRUE)
atchk_review("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-03_17_46_55.702125.csv"date_min="2024-09-03")
atchk_review("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-03_17_46_55.702125.csv",date_min="2024-09-03")
atcheck_review("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-03_17_46_55.702125.csv",date_min="2024-09-03")
atcheck_review("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-03_17_46_55.702125.csv",date_min="2024-09-03",min_passed=3)
#This is the master script for initial data analysis steps
#It identifies data to use, wrangles it into a usable form, creates additional variables based on this data, and creates plots of certain variables for quality-checking.
library(qualtRics)
library(tidyverse)
library(ddpcr)
library(tidyverse)
library(sigmoid)
##SET MANUALLY
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_s22fu <- "~/projects/s22_follow_up/"
path_to_rva <- "~/projects/RVA/"
ids_to_exclude <- c("6398dc9eee4c333e1712e777") #Ps whose data you don't want to analyze even if it looks good
##############
#clear out results from old analyses
system("mv /Users/dp/projects/RVA_2/analysis_data/*.csv /Users/dp/projects/RVA_2/analysis_data/old_analysis_data") #move any CSV files in this folder to old_analysis_data folder
system("rm -rf /Users/dp/projects/RVA_2/analysis_data/qc_plots/trial_level_vars/*") #clear the folder containing trial-level plots
system("rm -f /Users/dp/projects/RVA_2/analysis_data/qc_plots/sub_level_variables.pdf") #remove old subject level variable plot
#read in necessary functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22fu,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_wrangle_psychopy_data.R"))
csvs_to_analyze <- get_csvs_to_analyze(path_to_project_directory,ids_to_exclude,first_time="2024-09-03") #get the usable CSVs to analyze
all_data <- lapply(csvs_to_analyze, rva2_wrangle_psychopy_data) #reformats each CSV, turning it into a long dataset usable for analysis, and adds all variables of interest that can be created from the raw data alone.
#Returns a list - one element for each subject - where each element is itself a list containing dfs with the trial-level data and subject-level data
trials_list <- lapply(all_data, function(l) l[[1]]) #get a list of the trial-level dfs only
trial_level_data <- do.call(rbind,trials_list) #stack trial dfs into one big df
sub_list <- lapply(all_data, function(l) l[[2]]) #get a list of the subject-level dfs only
sub_level_data <- do.call(rbind,sub_list) #stack them into one big data frame
#append the Yes/No answer from qualtrics to this data
sub_level_data <- qualtrics_append(sub_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
trial_level_data <- qualtrics_append(trial_level_data,survey="/Users/dp/Downloads/RVA_2_survey.csv",id_col_qualt="participant",join_cols_qualt=c("Q46","Q40","Q41","Q37","Q25"),join_cols_df=c("sig_emot","age","gender","race","ethnicity"))
#write both to CSVs
date_time <- Sys.time() %>% chartr(" ","_",.) %>% chartr(":","_",.) #grab the date and time, reformatting ':' and '-' to  '_' so you can label the files with it
write.csv(trial_level_data,paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#write subject-level data
write.csv(sub_level_data,paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#Create plot grids of select variables for quality checking. These are saved to the qc_plots folder
tl_hists <- c("val_rat_rt","prob_rat_rt","val_rat","prob_rat") #trial level variables to plot
plot_trial_level_vars(trial_level_data,tl_hists,path_to_project_directory) #create and save plot grids
sl_hists <- c("answers_incorrect","instruct_keypress",
"feed_check_passed","aff_check_passed","worth_check_passed","att_checks_passed",
"probrat_skipped_percent","sd_probrat","mean_probrat_rt",
"valrat_skipped_percent","sd_valrat","mean_valrat_rt",
"earnings","total_experiment_time") #subject-level variables to plot
plot_sub_level_vars(sub_level_data,sl_hists,path_to_project_directory) #create and save plot grids
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/RVA_2/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_rva <- "~/projects/RVA/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_rva,"code/functions/rva_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva2_utilities.R"))
library(tidyverse)
library(cmdstanr)
library(bayesplot)
library(abind)
library(sigmoid)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-04_15_03_40.77831"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2024-09-04_15_03_40.77831.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-04_15_03_40.77831.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
answers_incorrect > 2 |
sd_valrat < .05 |
sd_probrat < .05 |
valrat_skipped_percent > .15 |
probrat_skipped_percent > .15 |
trials_completed < 80)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 3,subs$answers_incorrect[i] == 2,
subs$sd_valrat[i] < .07, subs$valrat_skipped_percent[i] > .10,
subs$sd_probrat[i] < .07, subs$probrat_skipped_percent[i] > .10)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude))
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
nrow(subs)
trials$id
subs$id
subs_to_exclude
21/101
at_review <- atcheck_review("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-04_15_03_40.77831.csv",date_min="2024-09-03",min_passed=3)
source("~/projects/ARL_bv/code/functions/arlbv_utilities.R", echo=TRUE)
at_review <- atcheck_review("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-04_15_03_40.77831.csv",date_min="2024-09-03",min_passed=3)
at_review$approve_ids
approves <- c(at_review$approve_ids,"64559feafbddb5f11010b973","643d681fb11898ee6b771ccf")
prolific_bp("/Users/dp/projects/RVA_2/analysis_data/sub_level_data_all_subs_2024-09-04_15_03_40.77831.csv",ids=approves)
6687ec5c42b4d3da563bace0 %in% approve_ids
"6687ec5c42b4d3da563bace0" %in% approve_ids
"6687ec5c42b4d3da563bace0" %in% approves
approves
"66c4e59ee03a1a6acd505024" %in% approves
""559e82dffdf99b7a9a124180"" %in% approves
559e82dffdf99b7a9a124180" %in% approves
"559e82dffdf99b7a9a124180" %in% approves
"62e0715747189999644b9868" %in% approves
"5a78b8355292b800012284ca" %in% approves
"60134392222eb41e037c9fde" %in% approves
"60134392222eb41e037c9fde" %in% at_review$approve_ids
approves[approves == "610ad34844dd2b51bf5d87f5"]
length(approves)
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2024-09-04_15_03_40.77831.csv"))
filter(subs,id %in% approves)
app_subs <- filter(subs,id %in% approves)
sum(app_subs$earnings)
383.19*1.33
apps_subs <- apps_subs %>% mutate(real_earn = if(earnings < 0, 0, earnings))
apps_subs <- apps_subs %>% mutate(real_earn = ifelse(earnings < 0, 0, earnings))
app_subs <- app_subs %>% mutate(real_earn = ifelse(earnings < 0, 0, earnings))
sum(app_subs$earnings)
sum(app_subs$real_earn)
434.32*1.33
434.32*1.3333333
